{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-21T18:17:47.237255700Z",
     "start_time": "2024-03-21T18:17:47.222808600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pprint import pprint, pformat\n",
    "import fitz  # Import the PyMuPDF library\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_openai  import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage, Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_csv_agent\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "\n",
    "from nanonets import NANONETSOCR\n",
    "\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Global variables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2935050485d80931"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_file = r\"N:\\Dev\\AI\\Underwriting\\data\\clients\\Safia Seyed\\Safia Seyed Paystub.pdf\"\n",
    "# Extracted tables:\n",
    "output_csvs_path = os.path.join(os.path.dirname(input_file), os.path.splitext(os.path.basename(input_file))[0] + \" extracted_tables\")\n",
    "os.makedirs(output_csvs_path, exist_ok=True)\n",
    "output_file = os.path.join(output_csvs_path, os.path.splitext(os.path.basename(input_file))[0] + \"_extracted_tables.csv\" )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T18:48:17.258715Z",
     "start_time": "2024-03-21T18:48:17.239050400Z"
    }
   },
   "id": "d1d23b00c80cc7b1",
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Nanonets OCR"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cdb9d15ab1a82f2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = NANONETSOCR()\n",
    "model.set_token(os.getenv(\"NANONESTS_TABLE_MODEL_TOKEN\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T18:49:02.108630600Z",
     "start_time": "2024-03-21T18:48:58.936189800Z"
    }
   },
   "id": "815568616691eebc",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.convert_to_csv(input_file, output_file_name=output_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T18:51:24.758612300Z",
     "start_time": "2024-03-21T18:49:02.109630200Z"
    }
   },
   "id": "78e794547daeaade",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parse CSV"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dce6ebf86c5b9c8a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def extract_tables(csv_file_path, output_csvs_path):\n",
    "    # Extract directory and base name without extension\n",
    "    csv_directory = os.path.dirname(csv_file_path)\n",
    "    csv_base_name = os.path.basename(csv_file_path)\n",
    "    csv_name_without_ext = os.path.splitext(csv_base_name)[0]\n",
    "\n",
    "    # Create output folder path\n",
    "    output_folder = output_csvs_path#os.path.join(csv_directory, csv_name_without_ext)\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Initialize variables\n",
    "    current_table_number = 0\n",
    "    current_table_lines = []\n",
    "    table_started = False\n",
    "    table_paths = []  # Initialize an empty list to store file paths\n",
    "\n",
    "    # Read the CSV file\n",
    "    with open(csv_file_path, 'r', newline='') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            # Convert row list to string to check if it's a table header\n",
    "            row_str = ','.join(row)\n",
    "            if row_str.startswith('TABLE '):\n",
    "                # If we're already in a table, save the current table\n",
    "                if table_started:\n",
    "                    path = save_table(current_table_lines, current_table_number, output_folder)\n",
    "                    table_paths.append(path)  # Add the path to the list\n",
    "                    current_table_lines = []  # Reset for the next table\n",
    "                current_table_number += 1\n",
    "                table_started = True  # Start a new table\n",
    "            elif table_started:\n",
    "                # Add row to current table\n",
    "                current_table_lines.append(row)\n",
    "\n",
    "    # Save the last table after file ends\n",
    "    if table_started:\n",
    "        save_table(current_table_lines, current_table_number, output_folder)\n",
    "        table_paths.append(path)  # Add the path to the list\n",
    "        \n",
    "    return table_paths\n",
    "\n",
    "def save_table(table_lines, table_number, output_folder):\n",
    "    output_file_path = os.path.join(output_folder, f\"Table_{table_number}.csv\")\n",
    "\n",
    "    # Check if the first row is empty or contains only commas\n",
    "    if not any(table_lines[0]) or all(cell == '' for cell in table_lines[0]):\n",
    "        table_lines = table_lines[1:]  # Remove the first row if it's empty\n",
    "\n",
    "    with open(output_file_path, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(table_lines)\n",
    "    print(f\"Table {table_number} saved to {output_file_path}\")\n",
    "    return output_file_path  # Return the path to the saved file\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T19:04:04.187984300Z",
     "start_time": "2024-03-21T19:04:04.175473100Z"
    }
   },
   "id": "590a809d2e8894b4",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1 saved to N:\\Dev\\AI\\Underwriting\\data\\clients\\Safia Seyed\\Safia Seyed Paystub extracted_tables\\Table_1.csv\n",
      "Table 2 saved to N:\\Dev\\AI\\Underwriting\\data\\clients\\Safia Seyed\\Safia Seyed Paystub extracted_tables\\Table_2.csv\n",
      "Table 3 saved to N:\\Dev\\AI\\Underwriting\\data\\clients\\Safia Seyed\\Safia Seyed Paystub extracted_tables\\Table_3.csv\n",
      "Table 4 saved to N:\\Dev\\AI\\Underwriting\\data\\clients\\Safia Seyed\\Safia Seyed Paystub extracted_tables\\Table_4.csv\n",
      "Table 5 saved to N:\\Dev\\AI\\Underwriting\\data\\clients\\Safia Seyed\\Safia Seyed Paystub extracted_tables\\Table_5.csv\n",
      "Table 6 saved to N:\\Dev\\AI\\Underwriting\\data\\clients\\Safia Seyed\\Safia Seyed Paystub extracted_tables\\Table_6.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "# csv_file_path = 'data/pdfs/Yash Paystub Nov 17 2023_extracted.csv'\n",
    "# csv_file_path = r'N:\\Dev\\AI\\Underwriting\\output3.csv'\n",
    "table_paths = extract_tables(output_file, output_csvs_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T19:04:05.566266900Z",
     "start_time": "2024-03-21T19:04:05.541254900Z"
    }
   },
   "id": "342895008cb87511",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N:\\\\Dev\\\\AI\\\\Underwriting\\\\data\\\\clients\\\\Safia Seyed\\\\Safia Seyed Paystub extracted_tables\\\\Table_1.csv', 'N:\\\\Dev\\\\AI\\\\Underwriting\\\\data\\\\clients\\\\Safia Seyed\\\\Safia Seyed Paystub extracted_tables\\\\Table_2.csv', 'N:\\\\Dev\\\\AI\\\\Underwriting\\\\data\\\\clients\\\\Safia Seyed\\\\Safia Seyed Paystub extracted_tables\\\\Table_3.csv', 'N:\\\\Dev\\\\AI\\\\Underwriting\\\\data\\\\clients\\\\Safia Seyed\\\\Safia Seyed Paystub extracted_tables\\\\Table_4.csv', 'N:\\\\Dev\\\\AI\\\\Underwriting\\\\data\\\\clients\\\\Safia Seyed\\\\Safia Seyed Paystub extracted_tables\\\\Table_5.csv', 'N:\\\\Dev\\\\AI\\\\Underwriting\\\\data\\\\clients\\\\Safia Seyed\\\\Safia Seyed Paystub extracted_tables\\\\Table_5.csv']\n"
     ]
    }
   ],
   "source": [
    "print(table_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T19:18:38.868773500Z",
     "start_time": "2024-03-21T19:18:38.859774800Z"
    }
   },
   "id": "9e193474a11f1c98",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# agent = create_csv_agent(\n",
    "#     OpenAI(temperature=0),\n",
    "#     \"data/data.csv\",\n",
    "#     verbose=True,\n",
    "#     agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "# )\n",
    "\n",
    "# chat_agent = create_csv_agent(\n",
    "#     ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\"),\n",
    "#     \"data/data.csv\",\n",
    "#     verbose=True,\n",
    "#     agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "# )\n",
    "\n",
    "multi_chat_agent = create_csv_agent(\n",
    "    ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\"),\n",
    "    table_paths,\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T19:19:01.610471Z",
     "start_time": "2024-03-21T19:19:01.551174800Z"
    }
   },
   "id": "1bf68785454d4029",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': 'df1.iloc[1, 3]'}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3m2.591,88\u001B[0m\u001B[32;1m\u001B[1;3mThe base salary is 2,591.88.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'The base salary is 2,591.88.'"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_chat_agent.run(\"What is the base salary?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T19:19:04.808773100Z",
     "start_time": "2024-03-21T19:19:02.291090600Z"
    }
   },
   "id": "634a52c870093c37",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mTo determine the start and end period of the payslip, we need to look for the relevant information in the dataframes. Specifically, we need to find the dates or time periods mentioned in the data.\n",
      "\n",
      "Unfortunately, the provided dataframes do not contain any information related to the start and end period of the payslip. The dataframes mainly consist of columns with labels and some numerical values, but there are no dates or time periods mentioned.\n",
      "\n",
      "Without any specific information about the start and end period in the data, it is not possible to determine the start and end period of the payslip.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'To determine the start and end period of the payslip, we need to look for the relevant information in the dataframes. Specifically, we need to find the dates or time periods mentioned in the data.\\n\\nUnfortunately, the provided dataframes do not contain any information related to the start and end period of the payslip. The dataframes mainly consist of columns with labels and some numerical values, but there are no dates or time periods mentioned.\\n\\nWithout any specific information about the start and end period in the data, it is not possible to determine the start and end period of the payslip.'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_chat_agent.run(\"What is the start and end period of this payslip?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T17:57:48.521317500Z",
     "start_time": "2024-03-21T17:57:46.044617300Z"
    }
   },
   "id": "749a1e4f8a7eeb8b",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ff3365f134d06aa4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
